import os
# TensorFlowのログ抑制
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import rasterio
from rasterio.windows import Window
from rasterio.enums import Resampling
import geopandas as gpd
import pandas as pd
import numpy as np
import glob
import random
import time
import zipfile
import gc
from shapely.geometry import Point

# 機械学習ライブラリ
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import tensorflow as tf
from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input

# =========================================================================
# 【設定】 全部入り・完全版 (All Indices + Fixed Normalization)
# =========================================================================
TARGET_BANDS = [
    "B02", "B03", "B04",      # 可視光
    "B05", "B06", "B07",      # Red Edge (作物種別用)
    "B08",                    # NIR (植生用)
    "B8A",                    # Narrow NIR
    "B11", "B12"              # SWIR (都市・水・土用)
]

# パス設定
SHP_PATH = r"G:\SATELITEIMAGE\RABI\MP\2025SENTINEL2\multiforestbunnruidata.scpx"
MAIN_IMAGE_DIR = r"G:\SATELITEIMAGE\RABI\MP\2025SENTINEL2\20250202"
SAFE_DIRS = [
    r"G:\SATELITEIMAGE\RABI\MP\2025SENTINEL2\20241114",
    r"G:\SATELITEIMAGE\RABI\MP\2025SENTINEL2\20241219",
    r"G:\SATELITEIMAGE\RABI\MP\2025SENTINEL2\20250118",
    r"G:\SATELITEIMAGE\RABI\MP\2025SENTINEL2\20250202",
    r"G:\SATELITEIMAGE\RABI\MP\2025SENTINEL2\20250319"
]
OUTPUT_DIR = r"G:\SATELITEIMAGE\RABI\MP\2025SENTINEL2"
OUTPUT_MAP = os.path.join(OUTPUT_DIR, "Final_All_Indices_Result.tif")

# 解析パラメータ
RADIUS_KM = 2.0
PATCH_SIZE = 32
UPSCALE_SIZE = 128
POINTS_PER_POLYGON = 30
BLOCK_SIZE = 512
BATCH_SIZE = 32
GRID_STRIDE = 1

# ★固定正規化の閾値 (川を消さないための重要設定)
MAX_PIXEL_VALUE = 3000.0 

# =========================================================================

# --- 1. 全部入り指数計算関数 (All 11 Indices) ---
def calc_all_indices(bands_dict):
    eps = 1e-6
    # 値の取り出し
    b2 = bands_dict["B02"] # Blue
    b3 = bands_dict["B03"] # Green
    b4 = bands_dict["B04"] # Red
    b5 = bands_dict["B05"] # RE1
    b6 = bands_dict["B06"] # RE2
    b8 = bands_dict["B08"] # NIR
    b11 = bands_dict["B11"] # SWIR1
    
    # 1. NDVI (植生)
    ndvi = (b8 - b4) / (b8 + b4 + eps)
    
    # 2. NDWI (水 - Gao/McFeeters) ★ご要望により復活
    # 水分量の把握に使います
    ndwi = (b3 - b8) / (b3 + b8 + eps)
    
    # 3. MNDWI (修正水指数) ★川の抽出に必須
    # 都市ノイズに強い水指数
    mndwi = (b3 - b11) / (b3 + b11 + eps)
    
    # 4. NDBI (都市)
    ndbi = (b11 - b8) / (b11 + b8 + eps)
    
    # 5. BSI (裸地)
    bsi = ((b11 + b4) - (b8 + b2)) / ((b11 + b4) + (b8 + b2) + eps)
    
    # 6. NDRE1 (作物種別 - Red Edge)
    ndre1 = (b8 - b5) / (b8 + b5 + eps)
    
    # 7. NDRE2 (作物種別 - Red Edge deep)
    ndre2 = (b8 - b6) / (b8 + b6 + eps)
    
    # 8. GNDVI (緑の質 - Green NDVI) ★復活
    gndvi = (b8 - b3) / (b8 + b3 + eps)
    
    # 9. MCARI (葉緑素吸収) ★復活
    mcari = ((b5 - b4) - 0.2 * (b5 - b3)) * (b5 / (b4 + eps))
    
    # 10. CI_rededge (クロロフィルインデックス)
    ci_re = (b8 / (b5 + eps)) - 1
    
    # 11. EVI (拡張植生指数) ★復活
    # 植生が濃い場所での飽和を防ぐ
    s = 10000.0
    evi = 2.5 * ((b8/s - b4/s) / (b8/s + 6*(b4/s) - 7.5*(b2/s) + 1 + eps))

    return [ndvi, ndwi, mndwi, ndbi, bsi, ndre1, ndre2, gndvi, mcari, ci_re, evi]

# --- 2. ファイル検索 ---
def find_band(safe_dir, band):
    pattern = os.path.join(safe_dir, "**", f"*{band}*.jp2")
    files = glob.glob(pattern, recursive=True)
    target = [f for f in files if "TCI" not in f and "PVI" not in f and ("_B" in f)]
    return target[0] if target else None

print("=== All-Indices Analysis System Initiated ===")

# --- 3. 画像パス特定 ---
print("1. データリンクを確立中...")
main_paths = {b: find_band(MAIN_IMAGE_DIR, b) for b in TARGET_BANDS}
if not all(main_paths.values()):
    missing = [b for b, p in main_paths.items() if p is None]
    raise FileNotFoundError(f"必須バンドが見つかりません: {missing}")

ts_paths = []
for d in SAFE_DIRS:
    found = {b: find_band(d, b) for b in TARGET_BANDS}
    if all(found.values()): ts_paths.append(found)

with rasterio.open(main_paths["B08"]) as src:
    base_profile = src.profile.copy()
    base_transform = src.transform
    base_crs = src.crs
    base_h, base_w = src.height, src.width

# --- 4. データ抽出コアロジック ---
def get_features_at_point(p_geom, return_image=True):
    try:
        # A. 視覚特徴 (CNN - Texture)
        input_img = None
        if return_image:
            py, px = ~base_transform * (p_geom.x, p_geom.y)
            px, py = int(px), int(py)
            half = PATCH_SIZE // 2
            if py < half or py >= base_h-half or px < half or px >= base_w-half: return None, None
            
            win = Window(px - half, py - half, PATCH_SIZE, PATCH_SIZE)
            with rasterio.open(main_paths["B08"]) as s8, \
                 rasterio.open(main_paths["B04"]) as s4, \
                 rasterio.open(main_paths["B03"]) as s3:
                p8 = s8.read(1, window=win).astype('float32')
                p4 = s4.read(1, window=win).astype('float32')
                p3 = s3.read(1, window=win).astype('float32')
            
            img = np.dstack([p8, p4, p3])
            # ★固定正規化 (Textureを正しく認識させるため)
            img = np.clip(img / MAX_PIXEL_VALUE, 0, 1) * 255.0
            img_resized = tf.image.resize(img, (UPSCALE_SIZE, UPSCALE_SIZE))
            input_img = preprocess_input(img_resized)

        # B. 数値特徴 (SVM - Indices & Raw Bands)
        ts_features = []
        for paths in ts_paths:
            vals = {}
            for b_name in TARGET_BANDS:
                with rasterio.open(paths[b_name]) as src:
                    r, c = src.index(p_geom.x, p_geom.y)
                    if 0 <= r < src.height and 0 <= c < src.width:
                        vals[b_name] = src.read(1, window=Window(c, r, 1, 1))[0, 0].astype('float32')
                    else:
                        vals[b_name] = 0.0
            
            if all(v > 0 for v in vals.values()):
                indices = calc_all_indices(vals)
                # 生バンド(SWIR, RE含む) + 全指数
                # ここでリストの項目が全てSVMに入力されます
                ts_features.extend([vals["B11"], vals["B12"], vals["B05"], vals["B08"]])
                ts_features.extend(indices)
            else:
                ts_features.extend([0.0] * 15) # 4バンド + 11指数 = 15特徴量/時期

        return input_img, np.array(ts_features)
    except Exception:
        return None, None

# --- 5. 学習フェーズ ---
print("2. 教師データを学習中 (全指標)...")
extract_dir = os.path.dirname(SHP_PATH)
gpkg_name = "geometry.gpkg"
try:
    with zipfile.ZipFile(SHP_PATH, 'r') as z:
        if gpkg_name in z.namelist(): z.extract(gpkg_name, extract_dir)
    gdf = gpd.read_file(os.path.join(extract_dir, gpkg_name))
except: gdf = gpd.read_file(os.path.join(extract_dir, gpkg_name))

if gdf.crs != base_crs: gdf = gdf.to_crs(base_crs)

target_point = gdf.geometry.iloc[0].centroid
center_x, center_y = target_point.x, target_point.y
target_col = next((c for c in ['class_id', 'macroclass_id', 'C_ID'] if c in gdf.columns), gdf.columns[0])

X_img_buf, X_ts_buf, y_labels = [], [], []
print("   ポイントサンプリング開始...")

inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(UPSCALE_SIZE, UPSCALE_SIZE, 3), pooling='avg')
inception.trainable = False

for idx, row in gdf.iterrows():
    label = int(row[target_col])
    geom = row.geometry
    points = []
    if geom.geom_type in ['Polygon', 'MultiPolygon']:
        minx, miny, maxx, maxy = geom.bounds
        attempts = 0
        while len(points) < POINTS_PER_POLYGON and attempts < POINTS_PER_POLYGON*5:
            pnt = Point(random.uniform(minx, maxx), random.uniform(miny, maxy))
            if geom.contains(pnt): points.append(pnt)
            attempts += 1
    else: points.append(geom)

    for p in points:
        img_data, ts_data = get_features_at_point(p, return_image=True)
        if img_data is not None:
            X_img_buf.append(img_data)
            X_ts_buf.append(ts_data)
            y_labels.append(label)
            
    if len(y_labels) % 500 == 0: print(f"   ...{len(y_labels)}点", end="\r")

X_imgs = np.array(X_img_buf)
X_ts = np.array(X_ts_buf)
y = np.array(y_labels)

print(f"\n3. ハイブリッドモデル学習 (データ数: {len(y)})...")
X_img_feat = inception.predict(X_imgs, batch_size=32, verbose=0)
X_combined = np.concatenate([X_img_feat, X_ts], axis=1)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_combined)
svm = SVC(kernel='rbf', C=10.0, probability=False, random_state=42)
svm.fit(X_scaled, y)
print("   学習完了。")

# --- 6. マップ作成 ---
print("4. マップ作成実行 (Full Spec)...")
radius_m = RADIUS_KM * 1000.0
roi_min_x, roi_max_x = center_x - radius_m, center_x + radius_m
roi_min_y, roi_max_y = center_y - radius_m, center_y + radius_m

win_full = rasterio.windows.from_bounds(roi_min_x, roi_min_y, roi_max_x, roi_max_y, transform=base_transform)
roi_win = win_full.round_offsets().round_shape()
roi_h, roi_w = int(roi_win.height), int(roi_win.width)
roi_transform = rasterio.windows.transform(roi_win, base_transform)
print(f"   出力サイズ: {roi_w}x{roi_h}")

out_profile = base_profile.copy()
out_profile.update(height=roi_h, width=roi_w, transform=roi_transform, count=1, dtype=rasterio.uint8)

final_map = np.zeros((roi_h, roi_w), dtype=np.uint8)
half = PATCH_SIZE // 2

srcs = {} 
for t_idx, paths in enumerate([main_paths] + ts_paths): 
    key = 'main' if t_idx == 0 else t_idx - 1 
    srcs[key] = {}
    for b_name in TARGET_BANDS:
        srcs[key][b_name] = rasterio.open(paths[b_name])

start_time = time.time()

try:
    for r_blk in range(0, roi_h, BLOCK_SIZE):
        for c_blk in range(0, roi_w, BLOCK_SIZE):
            abs_r = roi_win.row_off + r_blk - half
            abs_c = roi_win.col_off + c_blk - half
            r_end = min(roi_h, r_blk + BLOCK_SIZE)
            c_end = min(roi_w, c_blk + BLOCK_SIZE)
            abs_h_blk = (r_end - r_blk) + 2*half
            abs_w_blk = (c_end - c_blk) + 2*half
            
            win_10m = Window(abs_c, abs_r, abs_w_blk, abs_h_blk)
            
            loaded = {}
            skip_block = False
            try:
                for key, band_srcs in srcs.items():
                    loaded[key] = {}
                    for b_name, src in band_srcs.items():
                        cur_w = src.width
                        if cur_w < base_w: 
                            scale = 0.5
                            read_win = Window(int(abs_c*scale), int(abs_r*scale), max(1, int(abs_w_blk*scale)), max(1, int(abs_h_blk*scale)))
                        else:
                            read_win = win_10m
                        data = src.read(1, window=read_win, out_shape=(int(abs_h_blk), int(abs_w_blk)), resampling=Resampling.bilinear)
                        loaded[key][b_name] = data.astype('float32')
            except: skip_block = True
            if skip_block: continue

            batch_imgs, batch_ts, coords = [], [], []
            valid_h, valid_w = r_end - r_blk, c_end - c_blk
            
            for br in range(0, valid_h, GRID_STRIDE):
                for bc in range(0, valid_w, GRID_STRIDE):
                    lr, lc = br + half, bc + half
                    if loaded['main']['B08'][lr, lc] == 0: continue

                    # 画像 (CNN) - Texture解析
                    p8 = loaded['main']['B08'][lr-half:lr+half, lc-half:lc+half]
                    if p8.shape != (PATCH_SIZE, PATCH_SIZE): continue
                    p4 = loaded['main']['B04'][lr-half:lr+half, lc-half:lc+half]
                    p3 = loaded['main']['B03'][lr-half:lr+half, lc-half:lc+half]
                    img = np.dstack([p8, p4, p3])
                    # ★固定正規化
                    img = np.clip(img / MAX_PIXEL_VALUE, 0, 1) * 255.0
                    
                    # 数値 (SVM) - 全11指標
                    ts_vec = []
                    for i in range(len(ts_paths)):
                        d = loaded[i]
                        p_vals = {b: d[b][lr, lc] for b in TARGET_BANDS}
                        indices = calc_all_indices(p_vals)
                        ts_vec.extend([p_vals["B11"], p_vals["B12"], p_vals["B05"], p_vals["B08"]])
                        ts_vec.extend(indices)
                        
                    batch_imgs.append(img)
                    batch_ts.append(np.array(ts_vec))
                    coords.append((br, bc))
                    
                    if len(batch_imgs) >= BATCH_SIZE:
                        imgs_t = tf.image.resize(np.array(batch_imgs), (UPSCALE_SIZE, UPSCALE_SIZE))
                        feats_i = inception.predict(preprocess_input(imgs_t), verbose=0)
                        feats_c = np.concatenate([feats_i, np.array(batch_ts)], axis=1)
                        preds = svm.predict(scaler.transform(feats_c))
                        for k, (lbr, lbc) in enumerate(coords):
                            final_map[r_blk+lbr, c_blk+lbc] = preds[k]
                        batch_imgs, batch_ts, coords = [], [], []

            if batch_imgs:
                imgs_t = tf.image.resize(np.array(batch_imgs), (UPSCALE_SIZE, UPSCALE_SIZE))
                feats_i = inception.predict(preprocess_input(imgs_t), verbose=0)
                feats_c = np.concatenate([feats_i, np.array(batch_ts)], axis=1)
                preds = svm.predict(scaler.transform(feats_c))
                for k, (lbr, lbc) in enumerate(coords):
                    final_map[r_blk+lbr, c_blk+lbc] = preds[k]

            elapsed = time.time() - start_time
            if (r_blk + c_blk) % (BLOCK_SIZE * 2) == 0:
                print(f"   Processing: {r_blk}/{roi_h}, {c_blk}/{roi_w} (Time: {elapsed/60:.1f}min)", end="\r")
            del loaded
            gc.collect()

except Exception as e:
    print(f"\nエラー: {e}")
    import traceback
    traceback.print_exc()

finally:
    for group in srcs.values():
        for s in group.values(): s.close()

print(f"\n保存中: {OUTPUT_MAP}")
with rasterio.open(OUTPUT_MAP, 'w', **out_profile) as dst:
    dst.write(final_map, 1)

print("=== 解析完了: 全指標を網羅した解析結果が出力されました ===")
